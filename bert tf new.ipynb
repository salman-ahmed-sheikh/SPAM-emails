{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "Nsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    if row is None or row is '':\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            tokens = row.split(\" \")[:maxtokens]\n",
    "        except:\n",
    "            tokens=\"\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r'[\\W\\d]', \"\", token)\n",
    "            token = token[:maxtokenlen] # truncate token\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "print(stopwords) # see default stopwords\n",
    "\n",
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 517401 rows and 2 columns!\n",
      "                       file                                            message\n",
      "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
      "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
      "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
      "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
      "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "filepath = \"emails.csv\"\n",
    "\n",
    "# Read the data into a pandas dataframe called emails\n",
    "emails = pd.read_csv(filepath)\n",
    "\n",
    "print(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0], emails.shape[1]))\n",
    "print(emails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# take a closer look at the first email\n",
    "print(emails.loc[0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    }
   ],
   "source": [
    "# Separate headers from the message bodies\n",
    "import email\n",
    "\n",
    "def extract_messages(df):\n",
    "    messages = []\n",
    "    for item in df[\"message\"]:\n",
    "        # Return a message object structure from a string\n",
    "        e = email.message_from_string(item)    \n",
    "        # get message body  \n",
    "        message_body = e.get_payload()\n",
    "        messages.append(message_body)\n",
    "    print(\"Successfully retrieved message body from e-mails!\")\n",
    "    return messages\n",
    "\n",
    "bodies = extract_messages(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My Dad is getting his new pacemaker on October 17th and should be released \\nfrom the hospital on the 18th.  I will be taking those two days off.\\n\\nBrenda:  Could you please get me a good temp to sit for me on those days and \\nlet me know what form I need to fill out.\\n\\nThanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April 16, 2001\\nNotice No.:  01-132\\n\\nList of Proposed Nominees\\nfor Election to the Board of Directors of\\nNYMEX Holdings, Inc.\\n\\n\\nPlease be advised that the following persons were recommended as proposed=\\n=20\\nnominees for the Board of Directors of NYMEX Holdings, Inc.:\\n\\n1.  Recommended ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nFrom: \\tLozano, Melba  \\nSent:\\tTuesday, September 25, 2001 10:45 AM\\nTo:\\tCrandall, Sean; Alonso, Tom; Fisher, Mark; Mallory, Chris; Richter, Jeff; Driscoll, Michael M.; Badeer, Robert\\nCc:\\tWalker, Chris; Meredith, Kevin\\nSubject:\\tEND OF MONTH - Tokens - WEST POWER\\nImportance:\\tHigh\\n\\nPle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good Morning Sara,\\n\\nQuestion- When we do a back to back trade with London \"Enron Credit .Com\" ( \\ni.e. London negotiates the trade, ENA documents the trade with the street, we \\nback to back the trade to London), shouldn't the confirmation between London \\nand ENA be in the name of Risk Managm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dude, you may have taken her charger cord!  She can't find hers.  Do you have \\ntwo now?  Ditto on your comment re: the man versus him music.  The \\npersonality is way, way out front.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0                     My Dad is getting his new pacemaker on October 17th and should be released \\nfrom the hospital on the 18th.  I will be taking those two days off.\\n\\nBrenda:  Could you please get me a good temp to sit for me on those days and \\nlet me know what form I need to fill out.\\n\\nThanks.\n",
       "1  April 16, 2001\\nNotice No.:  01-132\\n\\nList of Proposed Nominees\\nfor Election to the Board of Directors of\\nNYMEX Holdings, Inc.\\n\\n\\nPlease be advised that the following persons were recommended as proposed=\\n=20\\nnominees for the Board of Directors of NYMEX Holdings, Inc.:\\n\\n1.  Recommended ...\n",
       "2  \\nFrom: \\tLozano, Melba  \\nSent:\\tTuesday, September 25, 2001 10:45 AM\\nTo:\\tCrandall, Sean; Alonso, Tom; Fisher, Mark; Mallory, Chris; Richter, Jeff; Driscoll, Michael M.; Badeer, Robert\\nCc:\\tWalker, Chris; Meredith, Kevin\\nSubject:\\tEND OF MONTH - Tokens - WEST POWER\\nImportance:\\tHigh\\n\\nPle...\n",
       "3  Good Morning Sara,\\n\\nQuestion- When we do a back to back trade with London \"Enron Credit .Com\" ( \\ni.e. London negotiates the trade, ENA documents the trade with the street, we \\nback to back the trade to London), shouldn't the confirmation between London \\nand ENA be in the name of Risk Managm...\n",
       "4                                                                                                                    Dude, you may have taken her charger cord!  She can't find hers.  Do you have \\ntwo now?  Ditto on your comment re: the man versus him music.  The \\npersonality is way, way out front.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract random 10000 enron email bodies for building dataset\n",
    "import random\n",
    "bodies_df = pd.DataFrame(random.sample(bodies, 10000))\n",
    "\n",
    "# expand default pandas display options to make emails more clearly visible when printed\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "bodies_df.head() # you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 3978 spam emails!\n"
     ]
    }
   ],
   "source": [
    "filepath = \"fradulent_emails.txt\"\n",
    "with open(filepath, 'r',encoding=\"latin1\") as file:\n",
    "    data = file.read()\n",
    "    \n",
    "# split on a code word appearing close to the beginning of each email\n",
    "fraud_emails = data.split(\"From r\")\n",
    "\n",
    "print(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...\n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...\n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "4  Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_bodies = extract_messages(pd.DataFrame(fraud_emails,columns=[\"message\"],dtype=str))\n",
    "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\n",
    "\n",
    "fraud_bodies_df.head() # you could do print(fraud_bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\n",
    "EnronEmails = bodies_df.iloc[:,0].apply(tokenize)\n",
    "EnronEmails = EnronEmails.apply(stop_word_removal)\n",
    "EnronEmails = EnronEmails.apply(reg_expressions)\n",
    "EnronEmails = EnronEmails.sample(Nsamp)\n",
    "\n",
    "SpamEmails = fraud_bodies_df.iloc[:,0].apply(tokenize)\n",
    "SpamEmails = SpamEmails.apply(stop_word_removal)\n",
    "SpamEmails = SpamEmails.apply(reg_expressions)\n",
    "SpamEmails = SpamEmails.sample(Nsamp)\n",
    "\n",
    "raw_data = pd.concat([SpamEmails,EnronEmails], axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined data represented as numpy array is:\n",
      "(2000,)\n",
      "Data represented as numpy array is:\n",
      "[list(['from', 'mrsvikki', 'meadepaul', 'kruger', 'streetboksburg', 'southjohannesburg', 'provincerepublic', 'south', 'africahellore', 'transfer', 'of', '', '', 'usdtwenty', 'nine', 'million', 'united', 'state', 'dollari', 'mrsvikki', 'meade', 'auditor', 'general', 'prime', 'banks', 'south', 'africa', 'during', 'course', 'auditing', 'i', 'discovered', 'floating', 'fund', 'account', 'opened', 'bank', '', 'since', '', 'nobody', 'operated', 'this', 'account', 'again', 'after', 'going', 'old', 'files', 'records', 'i', 'discovered', 'owner', 'account', 'died', 'without', 'heir', 'hence', 'money', 'floating', 'i', 'remit', 'money', 'urgently', 'beforfeited', 'nothingthe', 'owner', 'account', 'mr', 'howard', 'sweeney', 'foreigner', 'miner', 'industrialisthe', 'made', 'millions', 'dollars', 'died', 'misteriously', 'since', '', 'person', 'knows', 'account', 'thing', 'concerning', 'it', 'my', 'investigation', 'proved', 'account', 'beneficiary', 'that', 'mrhoward', 'sweeney', 'death', 'manager', 'sweeney', 'coypty', 'sa', 'we', 'start', 'first', 'transfer', 'six', 'million', 'dollars', '', 'upon', 'successful', 'transaction', 'without', 'disappoint', 'side', 'shall', 'reapply', 'payment', 'remaining', 'amount', 'accountthe', 'amount', 'involved'])\n",
      " list(['froma', 'carl', 'eblontela', 'emaila', 'eblonmartinsfarmsecomdear', 'friendcnaturally', 'mail', 'come', 'surprisec', 'i', 'may', 'crave', 'indulgencec', 'im', 'mre', 'carl', 'eblonc', 'first', 'son', 'of', 'dodi', 'martins', 'eblonc', 'popular', 'black', 'farmer', 'zimbabwe', 'recently', 'murdered', 'land', 'dispute', 'countrye', 'i', 'apologise', 'for', 'invading', 'your', 'privacyc', 'but', 'pleasec', 'iappeal', 'exercise', 'little', 'patience', 'read', 'my', 'letterc', 'i', 'guarantee', 'wasted', 'timeei', 'contacting', 'youc', 'need', 'foreign', 'partner', 'country', 'become', 'necessary', 'due', 'plans', 'to', 'relocate', 'establish', 'private', 'company', 'regionc', 'as', 'present', 'political', 'instability', 'country', 'zimbabwec', 'does', 'encourage', 'financial', 'investment', 'environmentis', 'conducive', 'investment', 'security', 'not', 'insuredcjust', 'reported', 'international', 'mediaethis', 'land', 'problem', 'came', 'zimbabwean', 'president', 'mre', 'robert', 'mugabe', 'introduced', 'new', 'land', 'act', 'reform', 'wholly', 'affected', 'rich', 'white', 'farmers', 'black', 'farmerse', 'this', 'resulted', 'to', 'killing', 'mob', 'action', 'zimbabwean', 'war', 'veterans', 'some', 'lunatics', 'societye', 'infact', 'lot', 'people'])\n",
      " list(['from', 'desk', 'dr', 'henry', 'salami', 'the', 'audit', 'section', 'presidency', 'federal', 'republic', 'nigeria', '', 'attention', 'the', 'beneficiary', 'dear', 'sir', 're', 'payment', 'instruction', 'outstanding', 'claim', '', 'for', 'succinct', 'introduction', 'i', 'dr', 'henry', 'salami', 'named', 'section', 'federal', 'republic', 'nigeria', 'frn', 'the', 'presidency', 'mandated', 'audit', 'section', 'handle', 'foreign', 'contract', 'awarded', 'commissioned', 'since', '', 'till', 'date', 'based', 'file', 'forwarded', 'office', 'review', 'subsequent', 'payment', 'contracts', 'genuinely', 'awarded', 'commissionedbased', 'review', 'carried', 'claim', 'i', 'discovered', 'claim', 'laying', 'grossly', 'overinvoiced', 'inflated', 'magnitude', 'officials', 'contacted', 'provide', 'account', 'receive', 'fund', 'simply', 'code', 'conduct', 'bureau', 'permit', 'civil', 'servants', 'run', 'operate', 'foreign', 'account', 'you', 'presented', 'receive', 'fund', 'beneficiary', 'i', 'discovered', 'time', 'execute', 'contract', 'federal', 'republic', 'nigeria', 'contacted', 'officials', 'presented', 'beneficiary', 'contract', 'payment', 'falls', 'within'])\n",
      " ...\n",
      " list(['michelle', 'long', 'time', 'friend', 'mine', 'left', 'smk', 'mickey', 'sheinfeld', 'would', 'like', 'move', 'something', 'new', 'would', 'candidate', 'anything', 'need', 'or', 'anybody', 'else', 'might', 'think', 'ofthankslou', 'original', 'messagefrom', 'thrasher', 'judy', 'g', 'jthrasherakingumpcomenron', 'mailtoimceanotesthrashercjudygecjthrasherakingumpecomeenronenroncom', 'senttuesday', 'july', '', '', '', 'pmtolstolerenroncomsubject', '', 'doclou', 'thank', 'time', 'assistance', 'remember', 'i', 'interested', 'working', 'part', 'time', 'schedule', 'i', 'talk', 'bonnie', 'set', 'something', 'youi', 'receive', 'emailgood', 'talk', 'youjudy', 'thrasherlegal', 'assistantakin', 'gump', 'strauss', 'hauer', '', 'feld', 'pennzoil', 'place', 'south', 'tower', 'louisianahouston', 'tx', '', 'the', 'information', 'contained', 'email', 'message', 'intended', 'personal', 'confidential', 'use', 'recipients', 'named', 'above', 'this', 'message', 'may', 'attorneyclient', 'communication', 'andor', 'work', 'product', 'privileged', 'confidential', 'if', 'reader', 'message', 'intended', 'recipient', 'agent', 'responsible', 'delivering', 'intended', 'recipient', 'hereby', 'notified', 'received', 'document', 'error', 'review', 'dissemination', 'distribution', 'copying', 'message', 'strictly'])\n",
      " list(['ok', 'what', 'time', 'you', 'original', 'messagefrom', 'rybarski', 'amanda', 'sentwednesday', 'january', '', '', '', 'pmtomaggi', 'mikesubjectlet', 'know', 'leaving', 'today'])\n",
      " list(['start', 'date', '', 'hourahead', 'hour', '', 'no', 'ancillary', 'schedules', 'awarded', 'variances', 'detectedvariances', 'detected', 'load', 'schedule', 'log', 'messagesparsing', 'file', '', 'oportlandwestdeskcalifornia', 'schedulingiso', 'final', 'schedulestxterror', 'invalid', 'variant', 'type', 'conversion', 'energy', 'importexport', 'schedule', '', 'final', 'schedule', 'found', 'preferred', 'schedule', 'details', 'trans_type', 'final', 'sc_id', 'ectstca', 'mkt_type', '', 'trans_date', '', 'tie_point', 'pverde__devers', 'interchg_id', 'epmi_ciso_', 'engy_type', 'firm', 'load', 'schedule', '', 'variance', 'found', 'table', 'tblloads', 'details', 'hour', '', '', 'preferred', '', '', 'final', '', 'trans_type', 'final', 'load_id', 'sce', 'mkt_type', '', 'trans_date', '', 'sc_id', 'epmi'])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of combined data represented as numpy array is:\")\n",
    "print(raw_data.shape)\n",
    "print(\"Data represented as numpy array is:\")\n",
    "print(raw_data)\n",
    "\n",
    "# corresponding labels\n",
    "Categories = ['spam','notspam']\n",
    "header = ([1]*Nsamp)\n",
    "header.extend(([0]*Nsamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x/train_y list details, to make sure it is of the right form:\n",
      "1400\n",
      "[['mrse jumai abdul azadedear sircplease be my investor trusteeei wish write pleading investor trustee overcce millione my late husband rich oil contractor southafricac but death july th e he deposited sum ofcce usd safe keeping company europe debtreconciliation committee drcethe money made oil contract left instruction withthe drc release money wife son abdul time studyingc investor accompany us thecce million released us proper investmentc andalso welfare children left behind meei plead accept help act investor trustee tomanage cce million mee we arrange toinvest money companye we agreed give  cce million assistancec  expenses may occure processeall relevant documents shall forwarded upon indications assist projecte']\n",
      " ['']\n",
      " ['attnaci godwin ekpontu sanganac esqec a personal attorney mrfmrsmillerc expartriate formally countrys branch agipoil companynaocc lagose on april c  clientcmrmrse miller died fatal automobile accidente ever sincec ihave made several frantic extensive enquiries locate anyof late clients relatives whichc timec provedunsuccessfule after unfruitful attemptsc howeverc i decidedto trace relatives via internetethisc coursec explainsthis correspondence youe i contacted assist inrepartriating money left behind deceased client beforeit gets confiscated declared unserviceable repeatedlythreatened bank deposit large amount ofmoney lodgede for purposes securityc i cannot disclose theamount i sure commitment collaborate meerecentlyc bank issued notice provide nextofkinor account confiscatede since i unsuccesfullin locating relatives  years endless effortci seek consent present nextofkin thedeceasedc mrfmrs millere so proceeds venturecan remitted nominated account ie in theevent agree']\n",
      " ...\n",
      " ['']\n",
      " ['']\n",
      " ['ed the alcoa lawyer wants adopt terms enaalcoa inc master for purposes december deal eweb requested following provisiondefault rate shall mean lesser a per annum rate interest equal prime lending rate may time time published the wall street journal money rates day or published such day recent preceding day published plus two percent  exceed total fourteen percent  annually b maximum rate permitted applicable lawplease let hear you sara']]\n",
      "[1 1 1 1 0]\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffle(a, b):\n",
    "    p = np.random.permutation(len(b))\n",
    "    data = a[p]\n",
    "    header = np.asarray(b)[p]\n",
    "    return data, header\n",
    "\n",
    "# function for converting data into the right format, due to the difference in required format from sklearn models\n",
    "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\n",
    "def convert_data(raw_data,header):\n",
    "    converted_data, labels = [], []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        out = ' '.join(raw_data[i])\n",
    "        converted_data.append(out)\n",
    "        labels.append(header[i])\n",
    "        #print(i)\n",
    "    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    return converted_data, np.array(labels)\n",
    "\n",
    "raw_data, header = unison_shuffle(raw_data, header)\n",
    "\n",
    "# split into independent 70% training and 30% testing sets\n",
    "idx = int(0.7*raw_data.shape[0])\n",
    "# 70% of data for training\n",
    "train_x, train_y = convert_data(raw_data[:idx],header[:idx])\n",
    "# remaining 30% for testing\n",
    "test_x, test_y = convert_data(raw_data[idx:],header[idx:])\n",
    "\n",
    "print(\"train_x/train_y list details, to make sure it is of the right form:\")\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print(train_y[:5])\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "#import metrics libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-beb514e823a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each word in the email text, get the base form of the word and return the list of base words\n",
    "def split_into_lemmas(message):\n",
    "    print(message)\n",
    "    message = message[0].lower()\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to apply the count vectorizer(BOW) and TF-IDF transforms to a set of input features\n",
    "def features_transform(mail):\n",
    "    #get the bag of words for the mail text\n",
    "    bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(mail)\n",
    "    #print(len(bow_transformer.vocabulary_))\n",
    "    messages_bow = bow_transformer.transform(mail)\n",
    "    #print sparsity value\n",
    "    print('sparse matrix shape:', messages_bow.shape)\n",
    "    print('number of non-zeros:', messages_bow.nnz) \n",
    "    print('sparsity: %.2f%%' % (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1])))\n",
    "    #apply the TF-IDF transform to the output of BOW\n",
    "    tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "    messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "    #print(messages_tfidf.shape)\n",
    "    #return result of transforms\n",
    "    return messages_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1 = pd.DataFrame(train_x, columns = ['message'])\n",
    "train_y1 = pd.DataFrame(train_y, columns = ['label'])\n",
    "test_x1 = pd.DataFrame(test_x, columns = ['message'])\n",
    "test_y1 = pd.DataFrame(test_y, columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform training set features into a set of useful features to build models\n",
    "train_features=features_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_seq_length):\n",
    "    # tf hub bert model path\n",
    "    bert_path = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\" \n",
    "\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "    \n",
    "    \n",
    "    preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "    encoder_inputs = preprocessor(text_input)\n",
    "    encoder = hub.KerasLayer(bert_path,trainable=False)\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
    "    sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768].# just extract BERT features\n",
    "    \n",
    "    # train dense classification layer on top of extracted pooled output features\n",
    "    dense = tf.keras.layers.Dense(256, activation=\"relu\")(pooled_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dense)\n",
    "\n",
    "    model = tf.keras.Model(inputs=text_input, outputs=pred)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = build_model(maxtokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate variables\n",
    "#initialize_vars(sess)\n",
    "# Train model\n",
    "history = model.fit(train_x,train_y,validation_data=(test_x,test_y),epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email",
   "language": "python",
   "name": "email"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
