{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "Nsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    if row is None or row is '':\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            tokens = row.split(\" \")[:maxtokens]\n",
    "        except:\n",
    "            tokens=\"\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r'[\\W\\d]', \"\", token)\n",
    "            token = token[:maxtokenlen] # truncate token\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "print(stopwords) # see default stopwords\n",
    "\n",
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 517401 rows and 2 columns!\n",
      "                       file                                            message\n",
      "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
      "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
      "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
      "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
      "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "filepath = \"emails.csv\"\n",
    "\n",
    "# Read the data into a pandas dataframe called emails\n",
    "emails = pd.read_csv(filepath)\n",
    "\n",
    "print(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0], emails.shape[1]))\n",
    "print(emails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_sample = emails.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_sample.to_csv(\"email_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# take a closer look at the first email\n",
    "print(emails.loc[0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    }
   ],
   "source": [
    "# Separate headers from the message bodies\n",
    "import email\n",
    "\n",
    "def extract_messages(df):\n",
    "    messages = []\n",
    "    for item in df[\"message\"]:\n",
    "        # Return a message object structure from a string\n",
    "        e = email.message_from_string(item)    \n",
    "        # get message body  \n",
    "        message_body = e.get_payload()\n",
    "        messages.append(message_body)\n",
    "    print(\"Successfully retrieved message body from e-mails!\")\n",
    "    return messages\n",
    "\n",
    "bodies = extract_messages(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Per Don Black's request, attached is the East Position Report as of 4/30/01.  We are also delivering hard copies of this report to you.  If you have any questions, please let me know.  Thanks.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They are being contacted and should oppose if they think about it twice.\\nMike\\n\\n-----Original Message-----\\nFrom: Jeff.Dasovich@enron.com [mailto:Jeff.Dasovich@enron.com]\\nSent: Tuesday, July 17, 2001 10:56 AM\\nTo: MDay\\nSubject: RE: AB 23XX Bad Bill Alert\\n\\n\\n\\nI want to find out what the gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry, Please forward to anyone else who needs to see this.\\n\\nSue Mara\\nEnron Corp.\\nTel: (415) 782-7802\\nFax:(415) 782-7854\\n----- Forwarded by Susan J Mara/NA/Enron on 07/30/2001 02:11 PM -----\\n\\n\\n\\tJBennett &lt;JBennett@GMSSR.com&gt; 07/30/2001 02:07 PM \\t   To: \"Sue Mara (E-mail)\" &lt;smara@enron....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steve,\\n\\nI am glad you feel better.  \\n\\nPlease, let Debbie know that she should not hesitate\\nto call on me or Paula (or the rest of he Woodlands\\ncrowd if she needs help).  \\n\\n\\nVince\\n\\n\\n\\n\\n\\nstevestock@pagenetips.com on 01/31/2001 06:16:13 AM\\nTo: vince.j.kaminski@enron.com\\ncc:  \\nSubje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alert Posted:3:45 PM November 18, 2000: CGC Interruptible notice for Mon., \\n11/20/00 at 10 AM.\\n\\nATTENTION CGC INTERRUPTIBLE CUSTOMERS AND THEIR SHIPPERS:\\nEffective at 10 AM, Monday, November 20, 2000 and until further notice,  \\nChattanooga Gas Company (CGC)  is issuing a curtailment order f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0                                                                                                        Per Don Black's request, attached is the East Position Report as of 4/30/01.  We are also delivering hard copies of this report to you.  If you have any questions, please let me know.  Thanks.\\n\\n \n",
       "1  They are being contacted and should oppose if they think about it twice.\\nMike\\n\\n-----Original Message-----\\nFrom: Jeff.Dasovich@enron.com [mailto:Jeff.Dasovich@enron.com]\\nSent: Tuesday, July 17, 2001 10:56 AM\\nTo: MDay\\nSubject: RE: AB 23XX Bad Bill Alert\\n\\n\\n\\nI want to find out what the gr...\n",
       "2  Harry, Please forward to anyone else who needs to see this.\\n\\nSue Mara\\nEnron Corp.\\nTel: (415) 782-7802\\nFax:(415) 782-7854\\n----- Forwarded by Susan J Mara/NA/Enron on 07/30/2001 02:11 PM -----\\n\\n\\n\\tJBennett <JBennett@GMSSR.com> 07/30/2001 02:07 PM \\t   To: \"Sue Mara (E-mail)\" <smara@enron....\n",
       "3  Steve,\\n\\nI am glad you feel better.  \\n\\nPlease, let Debbie know that she should not hesitate\\nto call on me or Paula (or the rest of he Woodlands\\ncrowd if she needs help).  \\n\\n\\nVince\\n\\n\\n\\n\\n\\nstevestock@pagenetips.com on 01/31/2001 06:16:13 AM\\nTo: vince.j.kaminski@enron.com\\ncc:  \\nSubje...\n",
       "4  Alert Posted:3:45 PM November 18, 2000: CGC Interruptible notice for Mon., \\n11/20/00 at 10 AM.\\n\\nATTENTION CGC INTERRUPTIBLE CUSTOMERS AND THEIR SHIPPERS:\\nEffective at 10 AM, Monday, November 20, 2000 and until further notice,  \\nChattanooga Gas Company (CGC)  is issuing a curtailment order f..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract random 10000 enron email bodies for building dataset\n",
    "import random\n",
    "bodies_df = pd.DataFrame(random.sample(bodies, 10000))\n",
    "\n",
    "# expand default pandas display options to make emails more clearly visible when printed\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "bodies_df.head() # you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 3978 spam emails!\n"
     ]
    }
   ],
   "source": [
    "filepath = \"fradulent_emails.txt\"\n",
    "with open(filepath, 'r',encoding=\"latin1\") as file:\n",
    "    data = file.read()\n",
    "    \n",
    "# split on a code word appearing close to the beginning of each email\n",
    "fraud_emails = data.split(\"From r\")\n",
    "\n",
    "print(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...\n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...\n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "4  Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_bodies = extract_messages(pd.DataFrame(fraud_emails,columns=[\"message\"],dtype=str))\n",
    "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\n",
    "\n",
    "fraud_bodies_df.head() # you could do print(fraud_bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\n",
    "EnronEmails = bodies_df.iloc[:,0].apply(tokenize)\n",
    "EnronEmails = EnronEmails.apply(stop_word_removal)\n",
    "EnronEmails = EnronEmails.apply(reg_expressions)\n",
    "EnronEmails = EnronEmails.sample(Nsamp)\n",
    "\n",
    "SpamEmails = fraud_bodies_df.iloc[:,0].apply(tokenize)\n",
    "SpamEmails = SpamEmails.apply(stop_word_removal)\n",
    "SpamEmails = SpamEmails.apply(reg_expressions)\n",
    "SpamEmails = SpamEmails.sample(Nsamp)\n",
    "\n",
    "raw_data = pd.concat([SpamEmails,EnronEmails], axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined data represented as numpy array is:\n",
      "(2000,)\n",
      "Data represented as numpy array is:\n",
      "[list([]) list([])\n",
      " list(['greetings', 'youdear', 'friendmy', 'name', 'mr', 'dennis', 'stevensonthechairman', 'board', 'directors', 'bank', 'ofscotland', 'united', 'kingdomi', 'written', 'seek', 'help', 'assistancei', 'wish', 'make', 'atransfer', 'money', 'involving', 'huge', 'amount', 'money', 'worth', 'fifteenmillion', 'pounds', 'sterlings', 'capounds', 'sterlingsi', 'amproposing', 'make', 'transfer', 'bank', 'account', 'choicethus', 'need', 'help', 'support', 'i', 'propose', 'offer', '', 'thetotal', 'amount', 'share', 'transfer', 'beensuccessfully', 'concluded', '', 'family', 'i', 'why', 'will', 'expenses', 'made', 'transfer', 'processkindlyreply', 'stating', 'interest', 'i', 'shall', 'give', 'details', 'andnecessary', 'proceedure', 'make', 'transferi', 'anxiously', 'awaityour', 'response', 'send', 'replies', 'dennistevenson_officeyahoocoukthanks', 'godbless', 'youthanks', 'god', 'bless', 'youmr', 'dennis', 'stevenson'])\n",
      " ...\n",
      " list(['will', 'computer', 'considered', 'income', 'item', 'tax', 'purposesthanks'])\n",
      " list(['karlathe', 'confirmation', 'group', 'resend', 'confirms', 'look', 'like', 'need', 'guys', 'sign', 'fax', 'back', 'us', 'our', 'fax', 'number', 'listed', 'below', 'let', 'know', 'need', 'anything', 'elsethankskim', 'original', 'messagefrom', 'wallumrod', 'ellen', 'sentwednesday', 'august', '', '', '', 'amtoward', 'kim', 's', 'houstonccdeming', 'richardsubjectre', 'palo', 'altokimsure', 'refax', 'confirmations', '', 'richard', 'please', 'take', 'care', 'this', 'yes', 'get', 'sign', 'fax', 'back', 'us', '', 'fax', 'number', 'regardsellenx', 'original', 'messagefrom', 'ward', 'kim', 's', 'houston', 'sentwednesday', 'august', '', '', '', 'amtowallumrod', 'ellensubjectpalo', 'altoellenpalo', 'alto', 'asked', 'refax', 'confirms', 'recently', 'sent', 'problems', 'fax', 'machine', 'also', 'need', 'sign', 'confirms', 'send', 'back', 'us', 'if', 'so', 'i', 'need', 'l', 'let', 'knowthanks', 'helpkim'])\n",
      " list(['sureconsider', 'done', 'original', 'messagefrom', 'gillette', 'lisa', 'senttuesday', 'september', '', '', '', 'pmtoscott', 'susan', 'msubjectre', 'love', 'niclasoohhh', 'going', 'grocery', 'store', 'could', 'please', 'pick', 'small', 'jar', 'dijonnaise', 'me', 'original', 'messagefrom', 'scott', 'susan', 'm', 'senttuesday', 'september', '', '', '', 'pmtogillette', 'lisasubjectre', 'love', 'niclasunfortunatebut', 'also', 'want', 'go', 'getting', 'attached', 'someone', 'ultimately', 'enough', 'common', 'sustain', 'kind', 'relationship', 'looking', 'foroff', 'soapboxim', 'going', 'grocery', 'store', 'forgot', 'things', 'dry', 'cleaners', 'running', 'finishing', 'laundry', 'detailso', 'take', 'bit', 'time'])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of combined data represented as numpy array is:\")\n",
    "print(raw_data.shape)\n",
    "print(\"Data represented as numpy array is:\")\n",
    "print(raw_data)\n",
    "\n",
    "# corresponding labels\n",
    "Categories = ['spam','notspam']\n",
    "header = ([1]*Nsamp)\n",
    "header.extend(([0]*Nsamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x/train_y list details, to make sure it is of the right form:\n",
      "1400\n",
      "[['mr laythank lunch yesterday i really enjoy spending time family as i mentioned yesterday i internal public relations suggestions review please feel free contact wish discuss further i would welcome opportunity expand suggestions help way deem necessary i ga make money back wednesday you thoughts prayersyours sincerelyamanda dayassociateenron north americasoutheast power']\n",
      " ['from the desk of dr richard akuezedirector project implementationnigerian national petroleumcorporation nnpc joint venturei strongly apologize unsolicited mail iam constrained circumstances surrounding myprofession i mandate colleagues inoffice solicite assistance deal wewant executethe business involves remittance ofusmtwenty eight million six hundred thousandunited states dollars bank account thecentral bank nigeria the money accrued throughdeliberate overinvoicing old projects executed forthe government foreign firms i fewofficials worked scheme benefit usalong foreign partner obliges us thematerials channel push fund ideabeing come thereafter share fund withwhoever assist usto make things easy legal fund reflectingin records payable foreigner aconsultancy service job ministry theturn around maintenance one petroleumrefineryall necessary relevant documents beprocured release transfer fund intoyour nominated accountplease get touch immediately myalternative']\n",
      " ['bev hansons firm planning event palm springs number legislators november    the notion connect legislators directly firms clients informal setting with lots golf dinners weve asked participate bev notified short ago promised details i told bev would interested participating more details follow  ']\n",
      " ...\n",
      " ['attn plsrecently bbc radio tv might watching hearing media  issue partaining family i mrs j taylor wife formal liberian president charles taylor who has exile nigeria country in west african since political unrest in liberian country my husband has west african country an assylombut recent united nation un demanded be tried befor liberian court law he reminded right nowthe life mine family certain nation treatning treat family ungodly manner  please first formost i need assistant help helpless family secure part family account hence husbands account has frozeen present administration however family decided search for good samaritan like help secure sum  thirty million two seventy thounsand us dollars  which rightly kept unsecured enviromenti belive one who']\n",
      " ['wowsoftball questions two thoughts  gentler lack of takeaway capacity issue steve would know play given socals position  did mckinsey check enron taking assignment from cal the lack conflict interest rules consultant world never ceases amaze me that said mckinsey probably best outfit could hope take investigation cal id like to call sure script ferc neg rate deals dovetails tell guys let know call be we may know tw ferc order says conversation mckinsey happens lets talk call thanks df from shelley cormanenronenronxgate   pmto mary kay milleretsenronenron drew fossumetsenronenron steven harrisetsenronenroncc subject cec interviewsmckinsey  co engaged state california evaluate conditions gas market california a mckinsey representative together cec staffer asked interview tw next wednesday mar  time']\n",
      " ['federal ministry of works and housingfederal secretariat complexfalomo ikoyi lagosfrom the office of engr babatunde pedrotel rebusiness proposaltransfer of usm twelve million four hundred thousandunited states dollars and business investment partnership dear friend partneri solicit strictest confidence proposal this virtue nature utterly confidential top secret introduced us nigeria chamber commerce foreign trade division we top government officials drawn federal ministry works housing fmwh presidency federal ministry finance fmf making contract review panel crp set present administration review contracts awarded past governmentin course work crp discovered grossly overinvoiced contracts awarded foreign contractors the contract duly executed commissioned leaving contract commission usm dollars floating escrow account central bank nigeria cbn ready paymentthe funds resulted connivance predecessors foreign contractors the contractors duly paid contractual entitlement usm dollars leaving overinvoiced funds usm dollars cbns escrow account we']]\n",
      "[0 1 0 1 1]\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffle(a, b):\n",
    "    p = np.random.permutation(len(b))\n",
    "    data = a[p]\n",
    "    header = np.asarray(b)[p]\n",
    "    return data, header\n",
    "\n",
    "# function for converting data into the right format, due to the difference in required format from sklearn models\n",
    "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\n",
    "def convert_data(raw_data,header):\n",
    "    converted_data, labels = [], []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        out = ' '.join(raw_data[i])\n",
    "        converted_data.append(out)\n",
    "        labels.append(header[i])\n",
    "        #print(i)\n",
    "    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    return converted_data, np.array(labels)\n",
    "\n",
    "raw_data, header = unison_shuffle(raw_data, header)\n",
    "\n",
    "# split into independent 70% training and 30% testing sets\n",
    "idx = int(0.7*raw_data.shape[0])\n",
    "# 70% of data for training\n",
    "train_x, train_y = convert_data(raw_data[:idx],header[:idx])\n",
    "# remaining 30% for testing\n",
    "test_x, test_y = convert_data(raw_data[idx:],header[idx:])\n",
    "\n",
    "print(\"train_x/train_y list details, to make sure it is of the right form:\")\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print(train_y[:5])\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score  \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "#import metrics libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each word in the email text, get the base form of the word and return the list of base words\n",
    "def split_into_lemmas(message):\n",
    "    #print(message)\n",
    "    message = message[0].lower()\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to apply the count vectorizer(BOW) and TF-IDF transforms to a set of input features\n",
    "def features_transform(mail):\n",
    "    #get the bag of words for the mail text\n",
    "    with open('train-features.pickle', 'rb') as handle:\n",
    "        train_x22 = pickle.load(handle)\n",
    "    #train_x22 = np.load('train-features.npy', allow_pickle=True)\n",
    "    bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(train_x22)\n",
    "    #print(len(bow_transformer.vocabulary_))\n",
    "    messages_bow = bow_transformer.transform(mail)\n",
    "    #print sparsity value\n",
    "    print('sparse matrix shape:', messages_bow.shape)\n",
    "    print('number of non-zeros:', messages_bow.nnz) \n",
    "    print('sparsity: %.2f%%' % (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1])))\n",
    "    #apply the TF-IDF transform to the output of BOW\n",
    "    tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "    messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "    #print(messages_tfidf.shape)\n",
    "    #return result of transforms\n",
    "    return messages_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1 = pd.DataFrame(train_x, columns = ['message'])\n",
    "train_y1 = pd.DataFrame(train_y, columns = ['label'])\n",
    "test_x1 = pd.DataFrame(test_x, columns = ['message'])\n",
    "test_y1 = pd.DataFrame(test_y, columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(600, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(train_x))\n",
    "print(test_x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (1400, 21031)\n",
      "number of non-zeros: 88432\n",
      "sparsity: 0.30%\n",
      "sparse matrix shape: (600, 21031)\n",
      "number of non-zeros: 31594\n",
      "sparsity: 0.25%\n"
     ]
    }
   ],
   "source": [
    "#transform training set features into a set of useful features to build models\n",
    "train_features=features_transform(train_x)\n",
    "#transform test features to test the model performance\n",
    "test_features=features_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function which takes in y test value and y predicted value and prints the associated model performance metrics\n",
    "def model_assessment(y_test,predicted_class):\n",
    "    print('confusion matrix')\n",
    "    print(confusion_matrix(y_test,predicted_class))\n",
    "    print('accuracy')\n",
    "    print(accuracy_score(y_test,predicted_class))\n",
    "    print('precision')\n",
    "    print(precision_score(y_test,predicted_class,pos_label=1))\n",
    "    print('recall')\n",
    "    print(recall_score(y_test,predicted_class,pos_label=1))\n",
    "    print('f-Score')\n",
    "    print(f1_score(y_test,predicted_class,pos_label=1))\n",
    "    print('AUC')\n",
    "    print(roc_auc_score(np.where(y_test==1,1,0),np.where(predicted_class==1,1,0)))\n",
    "    plt.matshow(confusion_matrix(y_test, predicted_class), cmap=plt.cm.binary, interpolation='nearest')\n",
    "    plt.title('confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('expected label')\n",
    "    plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create and fit NB model\n",
    "modelNB=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelNB.fit(train_features,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NB predictions\n",
    "predicted_class_NB=modelNB.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_x1.shape)\n",
    "print(test_features.shape)\n",
    "print(predicted_class_NB[0].shape)\n",
    "print(test_y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[294  11]\n",
      " [  0 295]]\n",
      "accuracy\n",
      "0.9816666666666667\n",
      "precision\n",
      "0.9640522875816994\n",
      "recall\n",
      "1.0\n",
      "f-Score\n",
      "0.9816971713810315\n",
      "AUC\n",
      "0.9819672131147541\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD2CAYAAAAj8rlYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAYfElEQVR4nO3de7hdVXnv8e8vARI0oHACNIbERIgoUAkhUGm0xssBxEqwR9pQFVAqaEGh3h5QjqJtDpyjYh+rqMELQTExKtQUqQhohSBCEg4BQojkQEg2REIUuZUAwff8Mceuk83ea4+1s2bmuvw+z7OePW9rjnetZL97zDHmHEMRgZlZjlF1B2BmncMJw8yyOWGYWTYnDDPL5oRhZtmcMMwsmxNGjVT4lqSHJd28Ded5raQ1rYytLpImS3pc0ui6Y7Hnk+/DqI+k1wILgf0i4om646mapHXA30XENXXHYiPjGka9Xgqs64VkkUPSDnXHYI05YWSSNEnSZZIekvRbSV9K20dJOkfSfZI2SbpE0ovSvimSQtKJktZL2izpE2nfycDXgcNTFfzTkk6StHRAuSFp37R8tKQ7JT0m6X5JH0nbZ0vqK73nlZL+Q9LvJa2SdExp38WSvizpx+k8N0naZ4jP3B//uyVtSJdO75N0qKTb0vm/VDp+H0k/S9/PZkmXSnpx2vdtYDLwb+nzfqx0/pMlrQd+Vtq2g6TdJfVJems6xzhJayWdsM3/oG0ifdbc10/qjpeI8GuYFzAaWAl8AXghMBZ4Tdr3HmAt8DJgHHAZ8O20bwoQwEXAzsBBwFPAK9P+k4ClpXKes562BbBvWt4IvDYt7wbMSMuzgb60vGOK5+PATsAbgMcoLnsALgZ+BxwG7ABcCiwa4nP3x//V9JmPALYA/wrsCUwENgGvS8fvC/x3YAywB3Ad8M+l860D3jTI+S9J3+vOpW07pGOOAH6TyrsI+EHd/x9a/H8rO2EAy+uO1zWMPIcBLwE+GhFPRMSWiOivCbwDuCAi7omIx4GzgbkDqtefjognI2IlReI5aIRxPAPsL2nXiHg4Im4Z5JhXUySu8yPi6Yj4GXAFcHzpmMsi4uaI2EqRMKYPU+4/ps/8U+AJYGFEbIqI+4HrgYMBImJtRFwdEU9FxEPABcDrMj7Xuel7fXLgjlTm94FrgbcAp2acr6NIynq1AyeMPJOA+9Iv2EAvAe4rrd9H8Zd7r9K235SW/5PiF3ok/gdwNHCfpF9IOnyIeDZExB8GxDRxG+J5sLT85CDr4wAk7SlpUbpcehT4DjB+mHMDbBhm/3zgQOBbEfHbjPN1FCeM7rMBmKzBG+UeoGi87DcZ2Mpzf6lyPQG8oH9F0p+Ud0bEsoiYQ1E9/1dg8RDxTJJU/redDNw/gniadR7F5cSrImJX4J1A+X/6UF1yQ3bVqehe/RrFZcv7+9tzuoUkRo0alfVqB+0RRfu7maL94HxJL5Q0VtKHVNz78KfAZyRNlTQO+F/A94aojQxnJXCApOmSxgLn9u+QtJOkd0h6UUQ8AzwKPDvIOW6iSDwfk7SjpNnAW4FFI4inWbsAjwO/lzQR+OiA/Q9StPXkuEjSJooECEVb0eeAS9Rl92i4htFlIuJZil+6fYH1QB/wSeDNFJcrW4FfAvdSNAp+YITl/Br4DHANcDewdMAh7wLWper++yj+gg88x9PAMSm2zcCFwAkRcddIYmrSp4EZwCPAjykagMvOA85JvSsfGeZclwD/QHFJc0L6N/jfFLWRs1oadc06KWH4xq0RSG0H50bEkWn9bICIOK/WwLqMpCnAFRFxYM2hVGbUqFExZsyYrGO3bNmyIiJmVhxSQ65hjMxEnttQ18dzGxXNsnVSDcN31o3MYP96rqpZ09opGeRwwhiZPoq2i35788fGObOmOGF0v2XANElTKbor5wJ/W29I1qnapcs0R+dE2kZSl+npwFXAamBxRKyqN6ruImkhcCOwX3qe5OS6Y6pKJ7VhuJfErEY77LBDjBuXd+PvI488UnsviS9JzGrWLrWHHE4YZjVzwjCzbE4YZpbNCcPMsvQ/rdopOifSNiTplLpj6Ha98B13UreqE8a26fr/zG2g67/jTkoYviQxq1m7JIMcbZUwVAx02lE6LeaDDz647hCaMmnSJGbMmNFR3/H69evZvHlzVhZop9pDjrZKGFa9G264oe4Qut6sWbOaOt4Jw8yyOWGYWbZO6lZ1wjCrkdswzKwpThhmls0Jw8yydVLC6JzWFrMu1ao7PSVNkvRzSaslrZJ0Rtp+rorpK29Nr6NL7zlb0lpJayQdOVwZrmGY1ajFD59tBT4cEbdI2gVYIenqtO8LEfG5AWXvTzEe7QEUc/JeI+nladKoQbmGYVazVtUwImJjRNySlh+jGG+20Xw5c4BFEfFURNwLrAUOa1SGE4ZZzap4+CzNGncwxVy7AKdLuk3SNyXtlrY1PSGXE4ZZzZpIGOMlLS+9Bn2SV8Wk4D8EzoyIR4GvAPsA0ykmFf98/6GDvL3hcztuwzCrUZO1h83DjRouaUeKZHFpRFwGEBEPlvZfBFyRVpuekMs1DLOatbCXRMA3gNURcUFp+4TSYW8D7kjLS4C5ksaomJRrGnBzozJcwzCrWQvvw5gFvAu4XdKtadvHgeMlTae43FgHnAoQEaskLQbupOhhOa1RDwk4YZjVrlXdqhGxlMHbJa5s8J55wLzcMpwwzGrkh8/MrClOGGaWzQnDzLI5YZhZNicMM8viRk8za4rH9DSzbK5hmFk2Jwwzy+I2DDNrihOGmWVzwjCzbE4YZpalxYMAV84Jw6xmrmGYWTYnDDPL5oRhZtmcMMwsi2/cMrOmOGGYWTZ3q5pZNtcwzCyL2zDMrCmdlDAqvXiSdJSkNZLWSjqryrLMOlUVs7dXpbKEIWk08GXgzcD+FNO17V9VeWadqpMSRpWXJIcBayPiHgBJi4A5FPM4mhmd9/BZlZFOBDaU1vvSNjMrcQ2jMNgnjOcdJJ0CnFJhHGZtrV2SQY4qaxh9wKTS+t7AAwMPioj5ETEzImZWGItZ22pVDUPSJEk/l7Ra0ipJZ6Ttu0u6WtLd6edupfecnTol1kg6crgyqkwYy4BpkqZK2gmYCyypsDyzjtTCS5KtwIcj4pXAq4HTUkfDWcC1ETENuDatk/bNBQ4AjgIuTJ0VQ6osYUTEVuB04CpgNbA4IlZVVZ5ZJ8pNFjkJIyI2RsQtafkxit+7iRSdDQvSYQuAY9PyHGBRRDwVEfcCayk6K4ZU6Y1bEXElcGWVZZh1uibaMMZLWl5anx8R84c45xTgYOAmYK+I2AhFUpG0ZzpsIvCr0tuG7ZjwnZ5mNWuiW3VzTlufpHHAD4EzI+LRBgkpq2OirHM6gM26UCsvSdL5dqRIFpdGxGVp84OSJqT9E4BNaXtWx0SZE4ZZzVrYSyLgG8DqiLigtGsJcGJaPhH4UWn7XEljJE0FpgE3NyrDlyRmNWvhfRizgHcBt0u6NW37OHA+sFjSycB64DiAiFglaTHF3ddbgdMi4tlGBQyZMCT9Cw2uZyLig018EDMbQqsSRkQsZfB2CYA3DvGeecC83DIa1TCWN9hnZi3SSXd6DpkwImJBeV3SCyPiiepDMusd7fScSI5hGz0lHS7pToqbQJB0kKQLK4/MrEeMGjUq69UOcqL4Z+BI4LcAEbES+IsqgzLrJV33tGpEbBgQcMOWVDPL1y7JIEdOwtgg6c+BSA+RfZB0eWJm26adag85ci5J3gecRnGP+f3A9LRuZi3QVZckEbEZeMd2iMWsJ7VLMsiR00vyMkn/JukhSZsk/UjSy7ZHcGa9oJNqGDmXJN8FFgMTgJcA3wcWVhmUWa9QGgS4m7pVFRHfjoit6fUdhnkE1szydVINo9GzJLunxZ+rmIRoEUWi+Bvgx9shNrOe0C7JIEejRs8VFAmi/9OcWtoXwD9WFZRZL+mKhBERU7dnIGa9qisSRpmkAymmOxzbvy0iLqkqKLNe0U7tEzmGTRiSPgXMpkgYV1LMlboUcMIwa4FOShg5vSRvpxh84zcR8W7gIGBMpVGZ9ZBO6lbNuSR5MiL+IGmrpF0pBhD1jVtmLdJJNYychLFc0ouBiyh6Th5nmIFCzSxP17VhRMTfp8WvSvoJsGtE3FZtWGa9oysShqQZjfb1T8lmZtumKxIG8PkG+wJ4Q4tjMetJXZEwIuL12zMQs17U//BZp/BERmY164oahpltH04YZpatKxJGo14SAPeSmLVGVyQM/thLMhaYCaykeNT9VcBNwGuqDc2s+3XajVtDNs9GxOtTT8l9wIyImBkRhwAHA2u3V4Bm3a6TRtzK6c95RUTc3r8SEXdQTDVgZi3QyofPJH0zDdZ9R2nbuZLul3Rreh1d2ne2pLWS1kg6crjz5zR6rpb0daB/LM934omMzFqmxbWHi4Ev8fzhJ74QEZ8bUO7+wFzgAIoBvq+R9PKIGHJmw5y09W5gFXAGcCZwZ9pmZtso93IkN6lExHXA7zKLnwMsioinIuJeiqaGwxq9Iefhsy2SvgpcGRFrMgMxs0xN1DDGS1peWp8fEfMz33u6pBOA5cCHI+JhitkMf1U6pi9tG1LOiFvHAJ8FdgKmSpoOfCYijskMNNshhxzC8uXLhz/QRqxdGs/sj5r4N9kcETNHUMRXKAbt7h+8+/PAe/jjAN9lDacQybkk+RRFNeX3ABFxKzAlP1Yza6TqXpKIeDAino2IP1CMa9N/2dEHTCodujfwQKNz5SSMrRHxyIgiNbNhVZ0wJE0orb4N6O9BWQLMlTRG0lRgGsMMjpXTS3KHpL8FRkuaBnwQ+GXzYZvZQK1+WlXSQopBu8dL6qO4QpidmhICWEeaYygiVklaTNGRsRU4rVEPCeQljA8AnwCeophn9So8iZFZy7SyXSkijh9k8zcaHD8PmJd7/pyE8ZaI+ARF0gBA0nEUkzKb2TbqpIbonLrQ2ZnbzGwEOunW8EZPq74ZOBqYKOmLpV27UlzvmNk2aqdkkKPRJckDFDd5HEMxvUC/x4B/qDIos17SFQkjIlYCKyVdDjzR33oqaTSe+cysZTopYeS0YfwU2Lm0vjNwTTXhmPWebpsqcWxEPN6/EhGPS3pBhTGZ9YxOa8PISVtPlIfrk3QI8GR1IZn1lq7oJSk5E/i+pP57zCcAf1NdSGa9pV2SQY6cx9uXSXoFsB/F0213RcQzlUdm1iO6KmGk9ooPAS+NiPdKmiZpv4i4ovrwzLpfJyWMnDaMbwFPA4en9T7gnyqLyKyHtHrErarlJIx9IuL/AM8ARMSTDD7whpmNQLd1qz4taWfSSDyS9qF4ctXMWqBdag85chLGp4CfAJMkXQrMAk6qMiizXtJVCSMirpZ0C/BqikuRMyJic+WRmfWAdmqfyJE7GfPrKKZGDGBH4PLKIjLrMV2VMCRdCOwLLEybTpX0pog4rdLIzHpEVyUMitrFgRHR3+i5ALi98VvMLFe79IDkyIl0DTC5tD4JuK2acMx6S6fdh5FTw/hvFPOr9g8/fijwK0lLAKqY0Misl7RLMsiRkzA+WXkUZj2s2xLGQxFxZ3mDpNkR8R/VhGTWWzopYeS0YSyW9DEVdpb0L8B5VQdm1is6qQ0jJ2H8GUWj5y+BZRSDA8+qMiizXtGNjZ7PUIywtTMwFrg3TepqZi3Qbd2qyygSxqEUd3seL+kHlUZl1kO6rYZxckQsT8u/AeZIeleFMZn1jHZKBjlyahgrJL1T0icBJE2muJnLzFqglTUMSd+UtEnSHaVtu0u6WtLd6edupX1nS1oraY2kI4c7f07CuJBitK3+WaEfA76cFb2ZDavFlyQXA0cN2HYWcG1ETAOuTetI2h+YCxyQ3nOhionKhpTVS5IeNNsCEBEPAzvlRm9mjbUyYUTEdcDvBmyeAyxIywuAY0vbF0XEUxFxL7AWOKzR+XMSxjMp6/Q/fLYH4F4SsxbZDo2ee0XERoD0c8+0fSKwoXRcX9o2pJxGzy9SjH+xp6R5wNuBc5qN2MyeT1Iz3arjJS0vrc+PiPnbUvwg26LRG3JG3LpU0grgjamAYyNi9cjiM7OBmqg9bI6ImSMo4kFJEyJio6QJwKa0vY/i6fN+e1PcmDmkrBG3IuIu4K4RBGpmw9gO3apLgBOB89PPH5W2f1fSBcBLgGnAzYOeIckdos/MKtLKhCFpITCb4vKlj2IQ7/Mpngk7GVgPHAcQEaskLQbuBLYCp0XEs43O74RhVqNW37gVEccPseuNQxw/D5iXe/7KbmIf7AYSM3u+Tro1vMqnXi7m+TeQmNkAnZQwKrskiYjrJE2p6vxm3aKTnlZ1G4ZZjdqp9pCj9oQh6RTgFIDJkycPc7RZ9+mkhFF7XSgi5kfEzIiYuccee9Qdjtl25zYMM8vWLskgR5XdqguBG4H9JPWlm0bMbADXMGh4A4mZJe2UDHL4ksSsZu5WNbNsrmGYWTYnDDPL4jYMM2uKE4aZZXPCMLNs7iUxsyxuwzCzpjhhmFk2Jwwzy+aEYWbZnDDMLIsbPc2sKe5WNbNsrmGYWTYnDDPL4jYMM2uKE4aZZXPCMLNsThhmlkVSS7tVJa0DHgOeBbZGxExJuwPfA6YA64C/joiHR3L+zukANutSFUwz8PqImB4RM9P6WcC1ETENuDatj4gThlnNtsO8JHOABWl5AXDsSE/khGFWsxYnjAB+KmlFmrcYYK+I2AiQfu450ljdhmFWsyaSwXhJy0vr8yNi/oBjZkXEA5L2BK6WdFdLgkycMMxq1GTtYXOpXWJQEfFA+rlJ0uXAYcCDkiZExEZJE4BNI43XlyRmNWvVJYmkF0rapX8ZOAK4A1gCnJgOOxH40UhjdQ3DrGYt7FbdC7g8JZcdgO9GxE8kLQMWpwnR1wPHjbQAJwyzmrXqxq2IuAc4aJDtvwXe2IoynDDMauSHz8ysKU4YZpbNCcPMsjlhmFk2Jwwzy9Lqp1Wr5oRhVjPXMMwsmxOGmWVzwjCzLL5xaxusWLFis6T76o6jCeOBzXUH0eU68Tt+aTMHO2GMUETsUXcMzZC0fLjHjW3b9MJ37IRhZtncrWpmWdyG0VsGDo9mrdf133EnJYzOqQu1oUHGU6yMpNmSrkjLx0gacqh4SS+W9PcjKONcSR/J3T7gmIslvb2JsqZIumO447bnd1yX7TBqeMs4YdRM0uhm3xMRSyLi/AaHvBhoOmFYPZwwrP8v6F2SFki6TdIPJL0g7Vsn6ZOSlgLHSTpC0o2SbpH0fUnj0nFHpXMsBf6qdO6TJH0pLe8l6XJJK9Prz4HzgX0k3Srps+m4j0palmL5dOlcn5C0RtI1wH4Zn+u96TwrJf2w/zMlb5J0vaRfS/rLdPxoSZ8tlX3qtn633cYJw/rtRzEU/KuAR3nuX/0tEfEa4BrgHOBNETEDWA58SNJY4CLgrcBrgT8ZoowvAr+IiIOAGcAqipmt/l+a/eqjko4AplGMID0dOETSX0g6BJgLHEyRkA7N+EyXRcShqbzVwMmlfVOA1wFvAb6aPsPJwCMRcWg6/3slTc0opyf0P3yW82oHbvSs1oaIuCEtfwf4IPC5tP699PPVwP7ADemvyE7AjcArgHsj4m4ASd8B+iemKXsDcAJARDwLPCJptwHHHJFe/zetj6NIILsAl0fEf6YylmR8pgMl/RPFZc844KrSvsUR8Qfgbkn3pM9wBPCqUvvGi1LZv84oqye0S+0hhxNGtaLB+hPpp4CrI+L48oGSpg/y/pEScF5EfG1AGWeOoIyLgWMjYqWkk4DZpX2DfV4BH4iIcmJB0pQmy+1anZQw2qOe070mSzo8LR8PLB3kmF8BsyTtCyDpBZJeDtwFTJW0T+n9g7kWeH9672hJu1LM3r1L6ZirgPeU2kYmqpgZ6zrgbZJ2VjGfxVszPtMuwEZJOwLvGLDvOEmjUswvA9akst+fjkfSy1XMmWHkt1+0S1JxDaNaq4ETJX0NuBv4ysADIuKh9Jd6oaQxafM5EfFrFXNj/ljSZopkc+AgZZwBzFcx58SzwPsj4kZJN6jotvz31I7xSuDG9B/vceCdEXGLpO8BtwL3AddnfKb/CdyUjr+d5yamNcAvKObHeF9EbJH0dYq2jVtUFP4Q2zAZcDdql2SQQxGtqvVaWapyXxERg/2SmwEwY8aMuP76nDwN48aNW1H3czWuYZjVrJNqGE4YFYmIdQx+CWH2X/q7VTuFE4ZZzVzDMLNsThhmlq2TEkbnXDyZdalW3oeRnj9aI2mtGjzRPFJOGGY1auWNWyqefP4y8GaKxw2Ol7R/K+N1wjCrWQtrGIcBayPinoh4GlgEzGllrG7DMKtZC7tVJwIbSut9wJ+16uTghGFWqxUrVlwlaXzm4WMlLS+tzx8wItlg1ZCW3srthGFWo4g4qoWn6wMmldb3Bh5o4fndhmHWRZYB0yRNlbQTxeBIOWOcZHMNw6xLRMRWSadTDCkwGvhmRKxqZRl+WtXMsvmSxMyyOWGYWTYnDDPL5oRhZtmcMMwsmxOGmWVzwjCzbE4YZpbt/wOBR6YgJkBtawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_assessment(test_y1,predicted_class_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-9823ac977f26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train-test.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtest_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 440\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[1;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[0;32m    728\u001b[0m                              \"allow_pickle=False\")\n\u001b[0;32m    729\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "with open('train-test.npy', 'rb') as f:\n",
    "    train_x = np.load(f)\n",
    "    train_y = np.load(f)\n",
    "    test_x = np.load(f)\n",
    "    test_y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.load('train-test.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"f.npy\", dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-features.pickle', 'rb') as handle:\n",
    "    dt1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-75d05469992d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-110-90f739b42a88>\u001b[0m in \u001b[0;36mfeatures_transform\u001b[1;34m(mail)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtrain_x22\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#train_x22 = np.load('train-features.npy', allow_pickle=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mbow_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_into_lemmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#print(len(bow_transformer.vocabulary_))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmessages_bow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbow_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \"\"\"\n\u001b[0;32m   1185\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1220\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1148\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "ff = features_transform(dt1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1 == train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([''], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mr laythank lunch yesterday i really enjoy spending time family as i mentioned yesterday i internal public relations suggestions review please feel free contact wish discuss further i would welcome opportunity expand suggestions help way deem necessary i ga make money back wednesday you thoughts prayersyours sincerelyamanda dayassociateenron north americasoutheast power'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-features.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_x, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-features.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['from george amachreegeneral manager financenigeria lng limitedc  c towersplot c sanusi fafunwa streetcvictoria islandcpe me be c marinac lagosenigeriaewwwenlngecomrea transfer of usdccetwenty millionc five hundred thousand united states dollars only to a safe accountesircit warmest pleasure writing confidential business offer irrespective factthat met done thing reimpose absolute confidence neverthelessc adage says day begins story line strong perspective i determined to communicate much conviction give proposal a second thought considerationeas earlier stated i mr daniel amachree general manager finance working nigeria liquefied natural gas nlnge my agency produce export nlg ngl safelyc reliably profitablec grow business full potentialc helping put flares nigeria and virtue unique position office general manager financee i elevated commission become chairman foreign contract tender board committee whose responsibility award supervise foreign contract ensure executed promptlyeconsequentlyc i chairman'],\n",
       "       ['hi everyoneonce i find tasked geof storey houston requested make lists applications use also consolidate files models data critical business i think mps count one directory network this items included proposed deal newco the calgary trading group set directory itradingnewco i think group would great each group probably one person charge directory overlap call sthanx chris'],\n",
       "       ['dear friendhow doing i would interested offeringyou parttime paying job could earn lotmy name kenneth scott i  years agei resigned job research scientist asia agriculturalresearch institute malaysia i work freelanceconsultant institute gives much time todo work basically freelance researcherwho could employed research institutes researchprojects anywhere worldcurrently i granted funding head researchproject tropical regions asia regarding rare andvulnerable plant species would commencing soonthis research program funded sponsored mycounterparts country but set back myassociates want make payments research form banktransfer check onlywhat i need you forat point i glad couldwork myrepresentative country you workingas paymentassistant charge collecting funds associatessince making payment form banktransferscheckto'],\n",
       "       ...,\n",
       "       [''],\n",
       "       [''],\n",
       "       ['meganim sure showing upi think must something name change enron midstream crestonelet pull oct  file see invoice  finalized im pretty sure paid usill try get later todaythankstheresa original messagefrom parker megan sentfriday october    amtostaab theresasubjectcrestone theresathere sale crestone oct  finaled unify does need billed megan  ole object picture device independent bitmap ']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mr laythank lunch yesterday i really enjoy spending time family as i mentioned yesterday i internal public relations suggestions review please feel free contact wish discuss further i would welcome opportunity expand suggestions help way deem necessary i ga make money back wednesday you thoughts prayersyours sincerelyamanda dayassociateenron north americasoutheast power'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
